# 2.1.7 Spark Cache

이번 챕터에서는 Spark 데이터 가공을 빠르고 효율적으로 하기 위한 Cache 기능에 대해 사례를 통해 살펴봅니다.



지난 챕터들에서 Spark 는 '논리적' 인 수준에서 데이터를 파티션 단위로 나누어 처리한다고 이야기를 나누었습니다. 다시 그림으로 살펴보면 아래와 같습니다.



![Cache Overview (https://www.nvidia.com/ko-kr/ai-data-science/spark-ebook/introduction-spark-processing/)](<../../.gitbook/assets/image (7).png>)



![Partition and Cache (https://www.nvidia.com/ko-kr/ai-data-science/spark-ebook/introduction-spark-processing/)](<../../.gitbook/assets/image (4).png>)



여기서 Worker Node 는 EC2 와 같은 개별 머신입니다. 하나의 EC2 에 여러개의 Executor (JVM) 을 실행할 수도 있습니다.&#x20;

개별 Executor 내의 설정에 의해 허용된 메모리량 만큼 Partition 데이터를 캐싱하는것이 가능하며, BlockManager 에 의해 관리됩니다. 만약 데이터가 메모리에 들어가기 충분하지 않으면 Disk 를 사용할 수 있습니다.

{% hint style="info" %}
[cache()](https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.cache.html?highlight=cache#pyspark.sql.DataFrame.cache) 함수는 persist(storageLevel = MEMORY\_AND\_DISK) 함수 와 동일합니다.



다른 Storage Level 은 무엇이 있나 찾아보고 논의해 봅시다.

* [https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-cache-table.html](https://spark.apache.org/docs/latest/sql-ref-syntax-aux-cache-cache-table.html)
{% endhint %}









